# Biblioteca de Transcri√ß√£o Plugg√°vel

Uma biblioteca Python flex√≠vel e modular para transcri√ß√£o de √°udio e v√≠deo usando m√∫ltiplos provedores de IA. Projetada com arquitetura plugg√°vel que permite f√°cil extens√£o e troca entre diferentes modelos de transcri√ß√£o.

## üöÄ Funcionalidades

- **üîå Arquitetura Plugg√°vel**: Troque facilmente entre diferentes provedores de transcri√ß√£o
- **üîÑ Fallback Inteligente**: Configure uma cadeia de provedores de fallback autom√°tico
- **üíæ Cache Autom√°tico**: Evita reprocessamento de arquivos j√° transcritos
- **üé¨ Suporte Multim√≠dia**: Transcri√ß√£o de arquivos de √°udio e v√≠deo
- **‚ö° Processamento Ass√≠ncrono**: Opera√ß√µes n√£o-bloqueantes para melhor performance
- **üìä Metadados Detalhados**: Retorna confian√ßa, tempo de processamento e segmentos com timestamp
- **üåê Configura√ß√£o Flex√≠vel**: Via vari√°veis de ambiente e arquivos de configura√ß√£o

## ü§ñ Provedores Suportados

### Distil-Whisper (PT-BR)
- **Modelo**: `freds0/distil-whisper-large-v3-ptbr`
- **Especialidade**: Otimizado para Portugu√™s do Brasil
- **Suporte**: GPU/CPU, cache local

### Faster-Whisper
- **Implementa√ß√£o**: Otimizada do Whisper para alta performance
- **Modelos**: small, medium, large-v2, large-v3
- **Suporte**: GPU/CPU, m√∫ltiplos idiomas

### Gemini (Google AI)
- **Funcionalidades**: Transcri√ß√£o de √°udio e v√≠deo
- **Especialidades**: Reconhecimento de texto visual em v√≠deos
- **Requisitos**: API Key do Google AI Studio

## üìÅ Estrutura do Projeto

```
transcription-library/
‚îú‚îÄ‚îÄ transcription_library/          # Pacote principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                # Exporta√ß√µes principais
‚îÇ   ‚îú‚îÄ‚îÄ core/                      # M√≥dulos centrais
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interfaces.py          # Interface base e tipos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.py             # Gerenciador de provedores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py               # Utilit√°rios compartilhados
‚îÇ   ‚îî‚îÄ‚îÄ providers/                 # Implementa√ß√µes dos provedores
‚îÇ       ‚îú‚îÄ‚îÄ distil_whisper_provider.py
‚îÇ       ‚îú‚îÄ‚îÄ faster_whisper_provider.py
‚îÇ       ‚îî‚îÄ‚îÄ gemini_provider.py
‚îú‚îÄ‚îÄ tests/                         # Testes unit√°rios e integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py               # Configura√ß√µes pytest
‚îÇ   ‚îú‚îÄ‚îÄ test_distil_whisper.py    # Testes Distil-Whisper
‚îÇ   ‚îú‚îÄ‚îÄ test_faster_whisper.py    # Testes Faster-Whisper
‚îÇ   ‚îú‚îÄ‚îÄ test_gemini.py            # Testes Gemini
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py       # Testes de integra√ß√£o
‚îú‚îÄ‚îÄ example.py                     # Exemplo de uso
‚îú‚îÄ‚îÄ pyproject.toml                 # Configura√ß√£o do pacote
‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias
‚îú‚îÄ‚îÄ pytest.ini                    # Configura√ß√£o de testes
‚îî‚îÄ‚îÄ README.md                      # Esta documenta√ß√£o
```

## üõ†Ô∏è Instala√ß√£o

### Pr√©-requisitos

1. **Python 3.8+**

2. **FFmpeg** (para an√°lise de arquivos de m√≠dia):
   ```bash
   # Ubuntu/Debian
   sudo apt install ffmpeg

   # macOS
   brew install ffmpeg

   # Windows
   # Baixar de https://ffmpeg.org/download.html
   ```

3. **PyTorch** (recomendado instalar antes para controlar vers√£o GPU/CPU):
   ```bash
   # CPU apenas
   pip install torch

   # GPU (CUDA 12.1)
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

4. **Chave API Gemini** (opcional):
   ```bash
   export GEMINI_API_KEY="sua_chave_api_aqui"
   ```

### Instala√ß√£o da Biblioteca

#### Via GitHub (Recomendado):
```bash
pip install git+https://github.com/seu_usuario/transcription-library.git
```

#### Para Desenvolvimento:
```bash
git clone https://github.com/seu_usuario/transcription-library.git
cd transcription-library
pip install -r requirements.txt
```

## üéØ Uso R√°pido

### Exemplo B√°sico

```python
import asyncio
from pathlib import Path
from transcription_library.core.manager import TranscriptionManager
from transcription_library.providers.distil_whisper_provider import DistilWhisperProvider

async def main():
    # Criar manager e registrar provedor
    manager = TranscriptionManager()
    provider = DistilWhisperProvider()
    manager.register_provider(provider.get_name(), provider)

    # Transcrever arquivo
    audio_file = Path("meu_audio.wav")
    result = await manager.transcribe_audio(audio_file, language="pt")

    if result.error_message:
        print(f"Erro: {result.error_message}")
    else:
        print(f"Transcri√ß√£o: {result.text}")
        print(f"Confian√ßa: {result.confidence:.2f}")
        print(f"Modelo usado: {result.model_used}")

asyncio.run(main())
```

### Exemplo com M√∫ltiplos Provedores e Fallback

```python
import asyncio
from transcription_library.core.manager import TranscriptionManager
from transcription_library.providers.distil_whisper_provider import DistilWhisperProvider
from transcription_library.providers.faster_whisper_provider import FasterWhisperProvider
from transcription_library.providers.gemini_provider import GeminiProvider
from transcription_library.core.config import settings

async def main():
    manager = TranscriptionManager()

    # Registrar m√∫ltiplos provedores
    manager.register_provider("distil-whisper-pt", DistilWhisperProvider())
    manager.register_provider("faster-whisper", FasterWhisperProvider())
    manager.register_provider("gemini-hybrid", GeminiProvider())

    # Configurar fallback
    settings.PRIMARY_PROVIDER = "distil-whisper-pt"
    settings.FALLBACK_PROVIDERS = ["faster-whisper", "gemini-hybrid"]
    settings.CONFIDENCE_THRESHOLD = 0.7

    # Transcrever (usar√° fallback se necess√°rio)
    result = await manager.transcribe_audio("audio.mp3", language="pt")
    print(f"Resultado: {result.text}")
    print(f"Provedor usado: {result.model_used}")

asyncio.run(main())
```

### Transcri√ß√£o de V√≠deo com Gemini

```python
import asyncio
from transcription_library.core.manager import TranscriptionManager
from transcription_library.providers.gemini_provider import GeminiProvider

async def main():
    manager = TranscriptionManager()
    gemini = GeminiProvider()
    manager.register_provider(gemini.get_name(), gemini)

    # Transcrever v√≠deo (detecta automaticamente √°udio vs v√≠deo)
    result = await manager.transcribe_audio("video.mp4", language="pt-BR")

    if not result.error_message:
        print("=== Resultado da Transcri√ß√£o de V√≠deo ===")
        print(result.text)

        # Gemini inclui marcadores estruturados:
        # [FALA]: transcri√ß√£o da fala
        # [TEXTO]: textos vis√≠veis na tela
        # [DESCRI√á√ÉO VISUAL]: descri√ß√£o do conte√∫do

asyncio.run(main())
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# Gemini API
export GEMINI_API_KEY="sua_chave_aqui"

# Caminhos personalizados (opcional)
export FFPROBE_PATH="/usr/local/bin/ffprobe"
export CUDNN_PATH="/usr/local/cuda/lib64"
```

### Configura√ß√£o Program√°tica

```python
from transcription_library.core.config import settings

# Configurar provedores
settings.PRIMARY_PROVIDER = "faster-whisper"
settings.FALLBACK_PROVIDERS = ["distil-whisper-pt", "gemini-hybrid"]
settings.CONFIDENCE_THRESHOLD = 0.8

# Configurar modelos
settings.FASTER_WHISPER_MODEL_SIZE = "large-v3"
settings.DISTIL_WHISPER_CACHE_DIR = "./meu_cache"
settings.MAX_VIDEO_SIZE_MB = 500
```

## üß™ Testes

A biblioteca inclui uma su√≠te completa de testes unit√°rios e de integra√ß√£o.

### Prepara√ß√£o para Testes

1. **Instalar depend√™ncias de teste:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Criar arquivos de sample:**
   - Coloque arquivos de √°udio/v√≠deo com "sample" no nome
   - Formatos suportados: `.wav`, `.mp3`, `.m4a`, `.mp4`, `.webm`, etc.
   - Locais: `./samples/`, `./test_files/`, `./data/`, Downloads

3. **Configurar API Gemini (opcional):**
   ```bash
   export GEMINI_API_KEY="sua_chave"
   ```

### Executar Testes

```bash
# Todos os testes
pytest

# Testes espec√≠ficos por provedor
pytest tests/test_distil_whisper.py
pytest tests/test_faster_whisper.py
pytest tests/test_gemini.py

# Testes de integra√ß√£o
pytest tests/test_integration.py

# Apenas testes r√°pidos (excluir lentos)
pytest -m "not slow"

# Apenas testes que n√£o precisam de API
pytest -m "not api"

# Testes com relat√≥rio detalhado
pytest -v --tb=short
```

### Marcadores de Teste

- `@pytest.mark.slow` - Testes que podem demorar >30s
- `@pytest.mark.gpu` - Testes que verificam GPU/CUDA
- `@pytest.mark.api` - Testes que requerem API externa
- `@pytest.mark.integration` - Testes de integra√ß√£o

### Limpeza de Mem√≥ria

Os testes incluem limpeza autom√°tica de mem√≥ria GPU entre execu√ß√µes:

```python
@pytest.fixture
def cleanup_gpu():
    yield
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()
```

## üìä Monitoramento e Status

```python
# Verificar status de todos os provedores
all_status = manager.get_all_providers_status()
for name, status in all_status.items():
    print(f"{name}: {status}")

# Status espec√≠fico
distil_status = manager.get_provider_status("distil-whisper-pt")
print(f"GPU Memory: {distil_status.get('cuda_available')}")
print(f"Cache Size: {distil_status.get('cache_size')}")

# Limpar caches
manager.clear_all_caches()
```

## üîß Desenvolvimento

### Adicionando Novos Provedores

1. **Implemente a interface:**
   ```python
   from transcription_library.core.interfaces import ITranscriptionProvider

   class MeuProvedor(ITranscriptionProvider):
       async def initialize(self) -> bool:
           # Carregar modelo/configurar API

       async def transcribe(self, audio_path, language) -> TranscriptionResult:
           # Implementar transcri√ß√£o

       def get_name(self) -> str:
           return "meu-provedor"
   ```

2. **Registre o provedor:**
   ```python
   provider = MeuProvedor()
   manager.register_provider(provider.get_name(), provider)
   ```

### Estrutura de Resultado

```python
@dataclass
class TranscriptionResult:
    text: str                          # Texto transcrito
    confidence: float                  # Confian√ßa (0.0-1.0)
    processing_time: float             # Tempo em segundos
    model_used: str                    # Nome do modelo
    language: str                      # Idioma detectado/usado
    segments: Optional[List[Dict]]     # Segmentos com timestamp
    error_message: Optional[str]       # Mensagem de erro
```

## üêõ Problemas Comuns

### Erro de Mem√≥ria GPU
```python
# Usar CPU for√ßadamente
settings.FORCE_CPU_FOR_DISTIL_WHISPER = True
settings.FASTER_WHISPER_FORCE_CPU = True
```

### FFprobe n√£o encontrado
```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# Ou configurar caminho manualmente
export FFPROBE_PATH="/usr/local/bin/ffprobe"
```

### Erro na API Gemini
```bash
# Verificar chave
echo $GEMINI_API_KEY

# Verificar limites de arquivo
# M√°ximo padr√£o: 200MB para v√≠deos
```

## üìù Contribui√ß√£o

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### Executar Testes Antes de Contribuir

```bash
# Testes r√°pidos para desenvolvimento
pytest -m "not slow and not api" -x

# Suite completa (se tiver recursos)
pytest -v
```

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a [Licen√ßa MIT](LICENSE).

## üôè Agradecimentos

- [Hugging Face Transformers](https://github.com/huggingface/transformers) - Distil-Whisper
- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) - Implementa√ß√£o otimizada
- [Google AI](https://ai.google.dev/) - API Gemini
- [OpenAI](https://openai.com/) - Modelo Whisper original

---

**Feito com ‚ù§Ô∏è para a comunidade de desenvolvedores**